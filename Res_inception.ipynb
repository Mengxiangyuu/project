{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b35d923-b9e9-4ea4-914a-5bf05b93a2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 忽略烦人的红色提示\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 获取计算硬件\n",
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f0ca03-de86-450d-a47e-6f0e7c19d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd21e05-6cd0-4e06-a0f1-a029a79ddf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_dir = '/home/featurize/work/HAM10000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf6544a-6af5-4b07-93df-d863157b9290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集路径 /home/featurize/work/HAM10000/train\n",
      "测试集路径 /home/featurize/work/HAM10000/val\n",
      "训练集图像数量 21255\n",
      "类别个数 7\n",
      "各类别名称 ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
      "测试集图像数量 5310\n",
      "类别个数 7\n",
      "各类别名称 ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dataset_dir, 'train')\n",
    "test_path = os.path.join(dataset_dir, 'val')\n",
    "print('训练集路径', train_path)\n",
    "print('测试集路径', test_path)\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(test_path, test_transform)\n",
    "\n",
    "print('训练集图像数量', len(train_dataset))\n",
    "print('类别个数', len(train_dataset.classes))\n",
    "print('各类别名称', train_dataset.classes)\n",
    "print('测试集图像数量', len(test_dataset))\n",
    "print('类别个数', len(test_dataset.classes))\n",
    "print('各类别名称', test_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f737200-3afd-46f7-9c42-52c66829572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = train_dataset.classes\n",
    "n_class = len(class_names)\n",
    "\n",
    "train_dataset.class_to_idx\n",
    "\n",
    "idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0baa451-a3c8-456a-a1ad-ea814dc9958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'AKIEC', 1: 'BCC', 2: 'BKL', 3: 'DF', 4: 'MEL', 5: 'NV', 6: 'VASC'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec89734-ec52-430c-a756-55faa2ce549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save('idx_to_labels.npy', idx_to_labels)\n",
    "np.save('labels_to_idx.npy', train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a787702d-61c6-41af-9cbd-19bc5d3baae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         )\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fef4d69-1e3a-4b7a-87bd-5495af6ef79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Inception, self).__init__()\n",
    "        self.branch1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "\n",
    "        self.branch3x3_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3_2 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.branch5x5_3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.branch_pool_conv = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "        branch5x5 = self.branch5x5_3(branch5x5)\n",
    "\n",
    "        branch_pool = self.branch_pool(x)\n",
    "        branch_pool = self.branch_pool_conv(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, num_layers):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.blocks.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                nn.SELU(inplace=True)\n",
    "            ))\n",
    "            in_channels = out_channels # for subsequent layers\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "            nn.SELU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        residual = self.shortcut(residual)\n",
    "        x += residual\n",
    "        return F.selu(x, inplace=True)\n",
    "\n",
    "class Inception_ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Inception_ResNet, self).__init__()\n",
    "        self.inception = Inception(in_channels=3)\n",
    "        self.resnet_1x3 = ResidualBlock(64, 256, kernel_size=3, stride=1, padding=1, num_layers=3)\n",
    "        self.resnet_2x4 = ResidualBlock(256, 128, kernel_size=3, stride=1, padding=1, num_layers=2)\n",
    "        self.resnet_3x6 = ResidualBlock(128, 1024, kernel_size=3, stride=1, padding=1, num_layers=6)\n",
    "        self.resnet_4x3 = ResidualBlock(1024, 512, kernel_size=3, stride=1, padding=1, num_layers=3)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.fc = nn.Linear(512 * 7 * 7, 7) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inception(x)\n",
    "        x = self.resnet_1x3(x)\n",
    "        x = self.resnet_2x4(x)\n",
    "        x = self.resnet_3x6(x)\n",
    "        x = self.resnet_4x3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = Inception_ResNet()\n",
    "\n",
    "# Model summary\n",
    "print(model)\n",
    "\n",
    "\n",
    "\n",
    "model = Inception_ResNet()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5146eb0-f25e-400c-bbd6-e567f8aab8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4fde230-042e-4e58-92eb-36d9febc8553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: scikit-learn in /environment/miniconda3/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6511cc9-d9d8-4c67-9aed-e1c0ac14dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(images, labels):\n",
    " \n",
    "\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images) \n",
    "    loss = criterion(outputs, labels) \n",
    "    \n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    _, preds = torch.max(outputs, 1) \n",
    "    preds = preds.cpu().numpy()\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    \n",
    "    log_train = {}\n",
    "    log_train['epoch'] = epoch\n",
    "    log_train['batch'] = batch_idx\n",
    "  \n",
    "    log_train['train_loss'] = loss\n",
    "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
    "   \n",
    "    \n",
    "    return log_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "709a01fc-05c8-4c4e-abca-6fcded8c838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_testset():\n",
    "  \n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader: \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images) \n",
    "\n",
    "           \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds = preds.cpu().numpy()\n",
    "            loss = criterion(outputs, labels) \n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            labels_list.extend(labels)\n",
    "            preds_list.extend(preds)\n",
    "        \n",
    "    log_test = {}\n",
    "    log_test['epoch'] = epoch\n",
    "    \n",
    "\n",
    "    log_test['test_loss'] = np.mean(loss_list)\n",
    "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
    "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
    "    \n",
    "    return log_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fee46b5e-4175-4de2-86d3-4f6159b99dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "batch_idx = 0\n",
    "best_test_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3760c516-8301-4455-9eeb-c3eaa63ae249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train_log = pd.DataFrame()\n",
    "log_train = {}\n",
    "log_train['epoch'] = 0\n",
    "log_train['batch'] = 0\n",
    "images, labels = next(iter(train_loader))\n",
    "log_train.update(train_one_batch(images, labels))\n",
    "df_train_log = df_train_log._append(log_train, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d11c0b7b-8482-4824-a46b-25c26ab804e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9233159</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch train_loss  train_accuracy\n",
       "0      0      0  1.9233159           0.125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af02f9ba-fa78-4164-8022-20205ff6e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练日志-测试集\n",
    "df_test_log = pd.DataFrame()\n",
    "log_test = {}\n",
    "log_test['epoch'] = 0\n",
    "log_test.update(evaluate_testset())\n",
    "df_test_log = df_test_log._append(log_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c8b30d7-3dd1-4b5e-98bf-8e07c1c334d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.547374</td>\n",
       "      <td>0.230697</td>\n",
       "      <td>0.13465</td>\n",
       "      <td>0.151779</td>\n",
       "      <td>0.138029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  test_loss  test_accuracy  test_precision  test_recall  test_f1-score\n",
       "0    0.0   2.547374       0.230697         0.13465     0.151779       0.138029"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb211f1a-64fc-497a-abf5-5639618a3784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmengxiangyu014\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/featurize/work/图像分类/3-【Pytorch】迁移学习训练自己的图像分类模型/wandb/run-20240330_165056-mi41a9ey</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mengxiangyu014/Skin_cancer/runs/mi41a9ey/workspace' target=\"_blank\">0330165055</a></strong> to <a href='https://wandb.ai/mengxiangyu014/Skin_cancer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mengxiangyu014/Skin_cancer' target=\"_blank\">https://wandb.ai/mengxiangyu014/Skin_cancer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mengxiangyu014/Skin_cancer/runs/mi41a9ey/workspace' target=\"_blank\">https://wandb.ai/mengxiangyu014/Skin_cancer/runs/mi41a9ey/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mengxiangyu014/Skin_cancer/runs/mi41a9ey?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe6e387b850>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    from typing import Literal\n",
    "except ImportError:\n",
    "    from typing_extensions import Literal\n",
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(project='Skin_cancer', name=time.strftime('%m%d%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45ea95c2-3059-4aed-9ffd-7818517d9229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:43<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.551.pth\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:45<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.584.pth\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.605.pth\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.627.pth\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:49<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.651.pth\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:45<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.676.pth\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:51<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.698.pth\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:45<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.701.pth\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.710.pth\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.715.pth\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:56<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.752.pth\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.766.pth\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.772.pth\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.775.pth\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.784.pth\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.806.pth\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:45<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.813.pth\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.813.pth\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:43<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.817.pth\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:43<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.825.pth\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.842.pth\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.843.pth\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:46<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.854.pth\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:46<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:48<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.858.pth\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:44<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.861.pth\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:46<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:57<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.863.pth\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [03:48<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.870.pth\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [04:09<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 checkpoint/best-0.872.pth\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    \n",
    "\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader): \n",
    "        batch_idx += 1\n",
    "        log_train = train_one_batch(images, labels)\n",
    "        df_train_log = df_train_log._append(log_train, ignore_index=True)\n",
    "        wandb.log(log_train)\n",
    "        \n",
    "    lr_scheduler.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    log_test = evaluate_testset()\n",
    "    df_test_log = df_test_log._append(log_test, ignore_index=True)\n",
    "    wandb.log(log_test)\n",
    "    \n",
    "   \n",
    "    if log_test['test_accuracy'] > best_test_accuracy: \n",
    "      \n",
    "        old_best_checkpoint_path = 'checkpoint/best-{:.3f}.pth'.format(best_test_accuracy)\n",
    "        if os.path.exists(old_best_checkpoint_path):\n",
    "            os.remove(old_best_checkpoint_path)\n",
    "      \n",
    "        best_test_accuracy = log_test['test_accuracy']\n",
    "        new_best_checkpoint_path = 'checkpoint/best-{:.3f}.pth'.format(log_test['test_accuracy'])\n",
    "        torch.save(model, new_best_checkpoint_path)\n",
    "        print('保存新的最佳模型', 'checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))\n",
    "     \n",
    "\n",
    "df_train_log.to_csv('训练日志-训练集.csv', index=False)\n",
    "df_test_log.to_csv('训练日志-测试集.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6512f03-53ff-428a-bff4-d151a2c57796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torch.load('checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2238ad86-508f-4a86-affd-fa6f8016e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 30, 'test_loss': 0.34036866, 'test_accuracy': 0.871939736346516, 'test_precision': 0.8792434679963509, 'test_recall': 0.8798923446960123, 'test_f1-score': 0.8791445234803907}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(evaluate_testset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
